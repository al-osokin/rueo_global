# Context: Legacy Parser Fix Task

## Quick Start

You're tasked with fixing a bug in the legacy parser (parser_v2.0_clean.py).

**Main document:** `/home/avo/rueo_global/PLAN_LEGACY_PARSER_FIX.md`

**Start here:** Phase 1, Task 1.1

## The Bug in 30 Seconds

**Article 10, line 3:**
```
—Å—á—ë—Ç—ã (_–ø—Ä–∏–±–æ—Ä_ = <globkalkulilo>, <bidkalkulilo>);
```

**Current output:** BROKEN
- Content: `[text: '—Å—á—ë—Ç—ã'], [text: ', )']` ‚Üê garbage!
- Result: Missing translation group

**Expected output:** WORKING
- Content: `[text: '—Å—á—ë—Ç—ã'], [note: '...']`
- Result: 4 groups (currently 3)

## Why This Matters

- Affects ALL numbered articles (1., 2., 3., ...)
- ~10k+ articles use `LexemeNumberedTemplate`
- Legacy parser handles these articles
- Bug loses translation data

## Project Context

### File Structure
```
backend/app/parsing/
‚îú‚îÄ‚îÄ parser_v2.0_clean.py        ‚Üê FIX HERE (1912 lines, legacy)
‚îú‚îÄ‚îÄ parser_v3/
‚îÇ   ‚îú‚îÄ‚îÄ text_parser.py          ‚Üê New parser (works correctly)
‚îÇ   ‚îú‚îÄ‚îÄ templates.py            ‚Üê Template selection
‚îÇ   ‚îú‚îÄ‚îÄ legacy_bridge.py        ‚Üê Bridge to old parser
‚îÇ   ‚îî‚îÄ‚îÄ normalization.py        ‚Üê Post-processing
```

### Why Legacy Parser Still Used?

- parser_v3 was supposed to replace it
- BUT most templates still delegate to legacy parser
- `LexemeNumberedTemplate` is one of them
- Rewriting templates = huge effort
- Fixing legacy parser = smaller effort

### Investigation Already Done

See `PARSER_ARCHITECTURE_NOTES.md` for:
- Root cause analysis
- What was tried
- Why it was postponed
- Architecture insights

## Your Mission

**Phase 1:** Understand WHERE the bug occurs (1-2 hours)
- Trace parsing flow
- Identify exact line numbers
- Create minimal reproduction

**Phase 2:** Design the fix (30-60 min)
- Analyze options
- Choose safest approach
- Write pseudocode

**Phase 3:** Implement fix (1-2 hours)
- Write tests FIRST
- Change code incrementally
- Test after each change

**Phase 4:** Validate (30-60 min)
- Test Article 10
- Regression test
- Sample reparse

**Phase 5 (OPTIONAL):** Full deployment
- Only if Phases 1-4 perfect
- Requires backup
- High risk

## Success Criteria (Phases 1-4)

- [ ] Article 10 creates 4 groups (not 3)
- [ ] Contains '—Å—á—ë—Ç—ã' translation
- [ ] No ', )' garbage in output
- [ ] Article 270: 24 groups (no regression)
- [ ] Article 383: 45 groups (no regression)
- [ ] Article 54: 3 items in [~iƒù/i] (Issue #5/#9 still works)

## Testing Commands

### Test Article 10
```python
from app.database import SessionLocal, init_db
from app.services.article_review import ArticleReviewService

init_db()
with SessionLocal() as session:
    payload, _ = ArticleReviewService(session).reparse_article('eo', 10)
    print(f"Groups: {len(payload['groups'])} (expected: 4)")
    
    # Check for '—Å—á—ë—Ç—ã'
    for g in payload['groups']:
        if '—Å—á—ë—Ç' in str(g['items']):
            print(f"Found: {g['items']}")
```

### Test Legacy Parser Directly
```python
from app.parsing.parser_v3.legacy_bridge import legacy_parser

article_text = """[abak/o] 1. _–∞—Ä—Ö–∏—Ç._ –∞–±`–∞–∫(–∞);
\t2. _–∏—Å—Ç._ –∞–±`–∞–∫(–∞), —Å—á—ë—Ç–Ω–∞—è –¥–æ—Å–∫`–∞ (_–¥—Ä–µ–≤–Ω–∏–π —Å—á—ë—Ç–Ω—ã–π –ø—Ä–∏–±–æ—Ä_);
\t3. —Å—á—ë—Ç—ã (_–ø—Ä–∏–±–æ—Ä_ = <globkalkulilo>, <bidkalkulilo>);
\t\tjapana ~ _—Å–º._ <sorobano>;
\t4. _–º–∞—Ç._ –∞–±`–∞–∫(–∞), –Ω–æ–º–æ–≥—Ä`–∞–º–º–∞."""

result = legacy_parser.parse_article(article_text)
block3 = [b for b in result['body'] if b.get('number') == 3][0]

print("Content:", block3.get('content'))
# Should have '—Å—á—ë—Ç—ã', NOT ', )'
```

### Regression Test
```python
from app.database import SessionLocal, init_db
from app.services.article_review import ArticleReviewService

init_db()
with SessionLocal() as session:
    service = ArticleReviewService(session)
    
    p270, _ = service.reparse_article('eo', 270)
    p383, _ = service.reparse_article('eo', 383)
    p54, _ = service.reparse_article('eo', 54)
    
    print(f"270: {len(p270['groups'])} (expect: 24)")
    print(f"383: {len(p383['groups'])} (expect: 45)")
    
    # Issue #5/#9 check
    for g in p54['groups']:
        if '~iƒù/i' in g.get('section', ''):
            print(f"54 [~iƒù/i]: {len(g['items'])} (expect: 3)")
```

## Important Files to Read

1. **PLAN_LEGACY_PARSER_FIX.md** - Complete plan (read this!)
2. **PARSER_ARCHITECTURE_NOTES.md** - Investigation findings
3. **Agents.md** - Project overview
4. **backend/app/parsing/parser_v2.0_clean.py** - The file to fix

## Communication

After EACH phase, report:
- Status: SUCCESS / PARTIAL / FAILED
- Key findings
- Next steps
- Any blockers

## Decision Tree

```
Phase 1 ‚Üí Can you find the bug location?
  Yes ‚Üí Proceed to Phase 2
  No ‚Üí STOP, report findings, ask for help

Phase 2 ‚Üí Can you design a safe fix?
  Yes ‚Üí Proceed to Phase 3
  No ‚Üí STOP, discuss alternatives

Phase 3 ‚Üí Do tests pass?
  Yes ‚Üí Proceed to Phase 4
  No ‚Üí Debug, or rollback and redesign

Phase 4 ‚Üí Any regressions?
  No ‚Üí SUCCESS! Consider Phase 5
  Yes ‚Üí STOP, analyze impact

Phase 5 ‚Üí Full reparse OK?
  Yes ‚Üí COMPLETE SUCCESS!
  No ‚Üí Rollback, document findings
```

## Risk Management

**Low Risk (Phases 1-2):** Research only, no code changes

**Medium Risk (Phase 3):** Code changes, but tested

**High Risk (Phase 4):** Integration testing

**Very High Risk (Phase 5):** Full deployment

**Always:** Can rollback with `git checkout parser_v2.0_clean.py`

## Expected Complexity

- **Phase 1:** ‚≠ê‚≠ê (2/5) - Research
- **Phase 2:** ‚≠ê‚≠ê‚≠ê (3/5) - Design
- **Phase 3:** ‚≠ê‚≠ê‚≠ê‚≠ê (4/5) - Implementation
- **Phase 4:** ‚≠ê‚≠ê‚≠ê (3/5) - Testing
- **Phase 5:** ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (5/5) - Deployment (OPTIONAL)

## Tips

1. **Don't rush:** Understand before changing
2. **Test continuously:** After every change
3. **Keep changes minimal:** Less code = less risk
4. **Document findings:** Help future debugging
5. **Ask questions:** Better than breaking things

## Starting Point

```python
# Your first command:
# Understand current behavior on Article 10

from app.parsing.parser_v3.legacy_bridge import legacy_parser

test_text = "—Å—á—ë—Ç—ã (_–ø—Ä–∏–±–æ—Ä_ = <globkalkulilo>, <bidkalkulilo>)"
result = legacy_parser.parse_rich_text(test_text)

print("Isolated parsing:", result)
# This should work (returns note correctly)

# Now test in full article context...
```

---

**Ready?** Start with Phase 1, Task 1.1 in PLAN_LEGACY_PARSER_FIX.md

**Questions?** Ask BEFORE making changes

**Good luck!** üöÄ
